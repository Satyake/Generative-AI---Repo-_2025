{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb648dd0-6370-45aa-b38c-bf630cc4827c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3f0a82ed-02f3-4f95-8a11-91f5b7839c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q langchain-openai langchain-huggingface chromadb langchain langchain_core langchain_chroma langchain-community langchain_groq bs4 beautifulsoup4 langchain_community faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba1d01fc-438d-4f12-87eb-91fafde78d04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile requirements.txt\n",
    "langchain\n",
    "ipykernel\n",
    "python-dotenv\n",
    "langchain-community\n",
    "pypdf\n",
    "bs4\n",
    "arxiv\n",
    "wikipedia\n",
    "PyMuPDF\n",
    "langchain-text-splitter\n",
    "langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e65bb31-8787-44f2-9329-e7ad23fa6903",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94a60c40-9daa-4bed-8863-f6e4cbc892ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement langchain-text-splitter (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for langchain-text-splitter\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install  -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec3639f2-1077-460f-8ccb-819507aeac26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "os.environ['GROQ_API_KEY']=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n",
    "llm=ChatGroq(model_name=\"Llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed67ff65-35fd-4402-8880-c79c1d5bf4ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5f1b68b758d4f13aa8a631646987fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb44cacee094346bb7027650d4cdb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae17b4c869b49ea999455dd6ae21387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844e732738254f48bc08c4b80118bd77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035b86b8b1a142fab38d3288f01129f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3600a33c794b09877909385eae6f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling%2Fconfig.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import TextLoader, PyPDFLoader, WebBaseLoader,ArxivLoader,WikipediaLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings_HF=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84dbd626-6f5d-46a0-9ac1-68e76a2323ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "loader=WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\",\"post-title\",\"post-header\")))\n",
    ",\n",
    ")\n",
    "\n",
    "docs=loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c56d8287-9e4b-4115-8a80-009f64fd8877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200)\n",
    "splits=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39227c7e-0ada-4434-b66a-8614c2d808a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore=Chroma.from_documents(documents=splits, embedding=embeddings_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af2adae5-9bb3-49da-a00b-6e66bf6fb5ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c2d41f7b-b8c1-44f3-8800-d2c6d1879df2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#PromptTemplate\n",
    "system_prompt=(\"\"\" your an assistant for QA Tasks\n",
    "Use the following pieces of indrmation to answer.\n",
    "If you dont know then do not answer unncessary \n",
    "information, always be concise use the context\n",
    "below\n",
    "{context}\n",
    "\"\"\"\n",
    ")\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "30e5f49b-555b-4ecc-9795-35f5e483ea69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(\n",
    "    llm,prompt)\n",
    "rag_chain=create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f81aad9a-4d4c-4621-a94a-9c4ab8db07b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response=rag_chain.invoke({\"input\":\"What is Self Reflection\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ecedec1-4028-4798-8602-3e2cf273616a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided information, Self-Reflection is a vital aspect in autonomous agents that allows them to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36619ea8-349e-49cd-a9b4-3f3844cd378c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the information provided, Tree of Thoughts (Yao et al. 2023) can be used to achieve task decomposition by:\\n\\n1. Decomposing the problem into multiple thought steps and generating multiple thoughts per step, creating a tree structure.\\n2. Using a search process such as BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\n\\nAdditionally, task decomposition can be done using:\\n\\n1. LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\"\\n2. Task-specific instructions; e.g. \"Write a story outline.\" for writing a novel.\\n3. Human inputs.'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adding chat history\n",
    "rag_chain.invoke({\"input\":\"How do we achieve it?\"})['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4362fec1-e32e-47f3-9984-e50e268148ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "237cb77e-aff3-4119-b5cd-9e4e5579516a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "history_aware_retriever=create_history_aware_retriever(llm,retriever,contextualize_q_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed6f8771-d208-41a6-abc1-12492c42cbd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "78fb643d-796d-4a6f-917c-8df983901603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "12c2ad31-ac7b-43ef-a413-e6b22316bd5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)\n",
    "rag_chain=create_retrieval_chain(history_aware_retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28219ebb-ae8c-4544-9042-446d420140e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"thoughts\": {\n",
      "        \"text\": \"Common ways to achieve self-reflection include showing two-shot examples to LLM and each example is a pair of (failed trajectory, ideal reflection for guiding future changes in the plan). Additionally, relying on an external classical planner to do long-horizon planning and utilizing the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem.\",\n",
      "        \"reasoning\": \"Common approaches to self-reflection\",\n",
      "        \"plan\": \"- Show two-shot examples to LLM\\n- Use Planning Domain Definition Language (PDDL) for long-horizon planning\",\n",
      "        \"criticism\": \"More research is needed to develop more effective self-reflection mechanisms\",\n",
      "        \"speak\": \"To achieve self-reflection, we can show two-shot examples to LLM or use PDDL for long-horizon planning.\"\n",
      "    },\n",
      "    \"command\": {\n",
      "        \"name\": \"none\",\n",
      "        \"args\": {}\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "chat_history=[]\n",
    "question=\"What is Self-reflection?\"\n",
    "response1=rag_chain.invoke({\"input\":question,\"chat_history\":chat_history})\n",
    "\n",
    "chat_history.extend(\n",
    "    [\n",
    "        HumanMessage(content=question),\n",
    "        AIMessage(content=response1['answer'])\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "question2=\"what are the common ways to achieve this?\"\n",
    "response2=rag_chain.invoke({\"input\":question2,\"chat_history\":chat_history})\n",
    "print(response2['answer'])\n",
    "                           \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe57baa4-e058-40c9-9f0b-be4b2c11dce0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is Self-reflection?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='According to the provided information, Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6be67cc-4aac-4446-9997-5d019a564006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195fe1af-c96a-46f9-8c9d-8ac4cc3ef326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basechathistory runnables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "27b26f45-774e-4627-89f0-30955087c6c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "7580b4b6-db36-4f2f-bd05-42c67c23842f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "store={}\n",
    "def get_session_history(session_id) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "conversational_rag_chain=RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "56e63483-40ad-4a82-81ce-93ec483b3a87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition is a process in which a complex task is broken down into smaller, more manageable steps or subtasks. This allows an agent, such as a computer program or a human, to plan and execute the task more effectively.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\":\"What is task decomposition\"},\n",
    "    config={\n",
    "        \"configurable\":{\"session_id\":\"abc123\"}\n",
    "    })['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07feffef-b4ed-4c5f-8257-6748e4ba572c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the provided information, there are three common ways to achieve task decomposition:\\n\\n1. Using LLM (Large Language Model) with simple prompting, such as \"Steps for XYZ.\\\\n1.\" or \"What are the subgoals for achieving XYZ?\"\\n2. Using task-specific instructions, such as \"Write a story outline.\" for writing a novel\\n3. With human inputs'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag_chain.invoke(\n",
    "    {\"input\":\"what are the common ways to achieve this?\"},\n",
    "    config={\n",
    "        \"configurable\":{\"session_id\":\"abc123\"}\n",
    "    })['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7217ef-747f-4580-be6a-c5683b00762b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
