{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881bd320-09d4-4bdd-8f82-380b420ca6d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#FAISS Facebook AI Similarity Search DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "519b946e-6e98-4fa6-8bbe-c2c87a673dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "deepspeed 0.10.3 requires pydantic<2.0.0, but you have pydantic 2.10.6 which is incompatible.\n",
      "gradient 2.0.6 requires attrs<=19, but you have attrs 23.1.0 which is incompatible.\n",
      "gradient 2.0.6 requires marshmallow<3.0, but you have marshmallow 3.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain_ollama langchain_community faiss-cpu langchain-openai langchain-text-splitters\n",
    "!pip install -q langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b42d062-e2b6-4717-ad36-5978a7ae03ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80a682c-1f08-4fe1-bce1-da5d940021af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 599, which is longer than the specified 200\n",
      "Created a chunk of size 617, which is longer than the specified 200\n",
      "Created a chunk of size 744, which is longer than the specified 200\n",
      "Created a chunk of size 299, which is longer than the specified 200\n",
      "Created a chunk of size 452, which is longer than the specified 200\n",
      "Created a chunk of size 777, which is longer than the specified 200\n",
      "Created a chunk of size 260, which is longer than the specified 200\n",
      "Created a chunk of size 530, which is longer than the specified 200\n",
      "Created a chunk of size 888, which is longer than the specified 200\n"
     ]
    }
   ],
   "source": [
    "loader=TextLoader('speech.txt')\n",
    "documents=loader.load()\n",
    "text_splitter=CharacterTextSplitter(chunk_size=200,\n",
    "                                    chunk_overlap=30)\n",
    "docs=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c1f6cf-3252-415c-9da3-aa3cc9b6d6dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282cb491-a687-490b-87b1-571e9b70e248",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-04 22:01:09.742367: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-02-04 22:01:09.742465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-02-04 22:01:09.744401: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-04 22:01:09.754644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-02-04 22:01:10.959245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91332ab80534408c847c22173ac04768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0c410049e9d40559397292bf0de7e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c15c85189740c3a3695c052a4d9a37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e03c8ca5d274a8ca4cadc31bd8e1776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9f6f40308241878ba2c9cb6567713d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee56ef1ca7a4391889b6bb4ef2e9288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31eae060a9a49b3bb435284c18d51b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "761880ef26af46d989329b3c78549985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350130f70e39464db275dee2b2a0b2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbde1b2e2d504ee5b0cff7427c0f8ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222cad9e662945349b98ba2d7ac30d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HF_embed=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "db=FAISS.from_documents(docs, HF_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25b928d8-864e-40c3-a02e-f4ed93d853fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##query\n",
    "query=\"What does the speaker believe is the main reason for US to enter the war?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba62ffb-c030-44d1-a525-6665bed3f8a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(id='35fdc516-9007-405b-947b-3fcca8d75c7e', metadata={'source': 'speech.txt'}, page_content=\"Speech is the use of the human voice as a medium for language. Spoken language combines vowel and consonant sounds to form units of meaning like words, which belong to a language's lexicon. There are many different intentional speech acts, such as informing, declaring, asking, persuading, directing; acts may vary in various aspects like enunciation, intonation, loudness, and tempo to convey meaning. Individuals may also unintentionally communicate aspects of their social position through speech, such as sex, age, place of origin, physiological and mental condition, education, and experiences.\"), Document(id='bdef3213-e204-41bd-9d94-0c62a8442e86', metadata={'source': 'speech.txt'}, page_content='Evolution\\nMain article: Origin of speech\\nAlthough related to the more general problem of the origin of language, the evolution of distinctively human speech capacities has become a distinct and in many ways separate area of scientific research.[2][3][4][5][6] The topic is a separate one because language is not necessarily spoken: it can equally be written or signed. Speech is in this sense optional, although it is the default modality for language.'), Document(id='03c5b5ae-56b2-440f-a1e7-0eb1b28d2a14', metadata={'source': 'speech.txt'}, page_content=\"While normally used to facilitate communication with others, people may also use speech without the intent to communicate. Speech may nevertheless express emotions or desires; people talk to themselves sometimes in acts that are a development of what some psychologists (e.g., Lev Vygotsky) have maintained is the use of silent speech in an interior monologue to vivify and organize cognition, sometimes in the momentary adoption of a dual persona as self addressing self as though addressing another person. Solo speech can be used to memorize or to test one's memorization of things, and in prayer or in meditation.\"), Document(id='63a26353-f6a5-4d06-a7e5-dd72087bdf96', metadata={'source': 'speech.txt'}, page_content=\"The evolutionary origin of speech is subject to debate and speculation. While animals also communicate using vocalizations, and trained apes such as Washoe and Kanzi can use simple sign language, no animals' vocalizations are articulated phonemically and syntactically, and do not constitute speech.\")]\n"
     ]
    }
   ],
   "source": [
    "docs=db.similarity_search(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f4126df-e358-40fa-8465-feb661efecb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3715d1c8-d86a-44cd-b887-d76e2838c4aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_db=FAISS.load_local(\"faiss_index\",HF_embed, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a6a1888-e7fd-4936-92c7-66effd733b03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs=new_db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc04168c-2fb0-4860-a290-45aaf8c93323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='35fdc516-9007-405b-947b-3fcca8d75c7e', metadata={'source': 'speech.txt'}, page_content=\"Speech is the use of the human voice as a medium for language. Spoken language combines vowel and consonant sounds to form units of meaning like words, which belong to a language's lexicon. There are many different intentional speech acts, such as informing, declaring, asking, persuading, directing; acts may vary in various aspects like enunciation, intonation, loudness, and tempo to convey meaning. Individuals may also unintentionally communicate aspects of their social position through speech, such as sex, age, place of origin, physiological and mental condition, education, and experiences.\"),\n",
       " Document(id='bdef3213-e204-41bd-9d94-0c62a8442e86', metadata={'source': 'speech.txt'}, page_content='Evolution\\nMain article: Origin of speech\\nAlthough related to the more general problem of the origin of language, the evolution of distinctively human speech capacities has become a distinct and in many ways separate area of scientific research.[2][3][4][5][6] The topic is a separate one because language is not necessarily spoken: it can equally be written or signed. Speech is in this sense optional, although it is the default modality for language.'),\n",
       " Document(id='03c5b5ae-56b2-440f-a1e7-0eb1b28d2a14', metadata={'source': 'speech.txt'}, page_content=\"While normally used to facilitate communication with others, people may also use speech without the intent to communicate. Speech may nevertheless express emotions or desires; people talk to themselves sometimes in acts that are a development of what some psychologists (e.g., Lev Vygotsky) have maintained is the use of silent speech in an interior monologue to vivify and organize cognition, sometimes in the momentary adoption of a dual persona as self addressing self as though addressing another person. Solo speech can be used to memorize or to test one's memorization of things, and in prayer or in meditation.\"),\n",
       " Document(id='63a26353-f6a5-4d06-a7e5-dd72087bdf96', metadata={'source': 'speech.txt'}, page_content=\"The evolutionary origin of speech is subject to debate and speculation. While animals also communicate using vocalizations, and trained apes such as Washoe and Kanzi can use simple sign language, no animals' vocalizations are articulated phonemically and syntactically, and do not constitute speech.\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b542c-294a-4e71-8054-390b74c63898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
