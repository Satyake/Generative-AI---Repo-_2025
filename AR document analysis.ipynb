{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install langchain_community faiss-cpu langchain-openai langchain-text-splitters langchain_huggingface pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Model Type**:\n",
      "   - **v3**: Not specifically mentioned in the excerpts.\n",
      "   - **v4**: Utilizes the LightGBM model among various other models as explained in the benchmarking analysis. \n",
      "     - *Excerpt*: \"The orange model is LightGBM, the green model is a Generalized Linear Model, the red model is a Gradient Boosted Model, the purple model is a Distributed Random Forest and the brown model is XGBoost.\"\n",
      "\n",
      "2. **Training Data Ranges**:\n",
      "   - **v3**: Not explicitly mentioned in the available excerpts.\n",
      "   - **v4**: Specifies the use of out-of-time validation data which is not used in model training.\n",
      "     - *Excerpt*: \"The following results are based solely on out-of-time validation data, which is not used in model training.\"\n",
      "\n",
      "3. **Feature Engineering and Number/Type of Features**:\n",
      "   - **v3**: Details not included in the available excerpts.\n",
      "   - **v4**: Elaborates on advanced statistical techniques for variable selection, including the use of Information Value determined by Weight of Evidence to remove unimportant predictors.\n",
      "     - *Excerpt*: \"Socure uses the Information Value determined by Weight of Evidence (WoE) to... Keep predictors that are robust over time and across clients.\"\n",
      "\n",
      "4. **Model Performance Metrics**:\n",
      "   - **v3**: Provides some performance metrics such as overall AUC and FDR/G:F ratios.\n",
      "     - *Excerpt*: \"Overall AUC Address Risk v2 (FDR/FP) Address Risk v3 (FDR/FP)... 73.6% 77.9%.\"\n",
      "   - **v4**: Outlines an improvement in AUC-ROC and FDR/G:F ratios.\n",
      "     - *Excerpt*: \"The new model outperforms the old model by 14.7% AUC-ROC and captures 29.9% more fraud in the riskiest 3 percent.\"\n",
      "\n",
      "5. **Validation Methodology**:\n",
      "   - **v3**: Specific validation methodologies were not described in the provided excerpts.\n",
      "   - **v4**: Employs out-of-time validation data for performance testing.\n",
      "     - *Excerpt*: \"The following results are based solely on out-of-time validation data.\"\n",
      "\n",
      "Based on the excerpts provided, the versions do not appear to be using the exact same model type as v4 highlights the use of LightGBM and other models in its framework, whereas there is no specific mention of the model type in v3.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "import os \n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_community.vectorstores import FAISS\n",
    "load_dotenv()\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "parser=StrOutputParser()\n",
    "directory_path=(\"documentation_addr\")\n",
    "loader=PyPDFDirectoryLoader(directory_path)\n",
    "documents=loader.load()\n",
    "text_splitter=CharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "docs=text_splitter.split_documents(documents)\n",
    "vectorstore=FAISS.from_documents(docs, embeddings)\n",
    "retriever=vectorstore.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     \"\"\"You are a senior model governance analyst. Your task is to compare two versions of a model report (v3 and v4) \n",
    "based on the provided document excerpts.\n",
    "\n",
    "Please identify and summarize all **important differences** between the two documents, specifically focusing on:\n",
    "\n",
    "- ✅ Model type (e.g., XGBoost, ensemble, etc.)\n",
    "- ✅ Feature engineering and number/type of features\n",
    "- ✅ Training data ranges (include exact date ranges, This is important do not miss this)\n",
    "- ✅ Validation methodology (holdout, OOT, blind review, etc.)\n",
    "- ✅ Model performance metrics (AUC, FDR, G:F ratio, etc.)\n",
    "- ✅ Reason codes, output format, compliance references (e.g., ECOA)\n",
    "- ✅ Any renaming, reversioning, or deployment differences\n",
    "\n",
    "For each difference, include:\n",
    "- A **clear numbered bullet point**\n",
    "- Whether it applies to **v3** or **v4** or both\n",
    "- A **short text excerpt** from the original source\n",
    "\n",
    "Do **not** include unimportant boilerplate or redundant information. Only highlight true differences or notable enhancements.\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"),\n",
    "    \"user\",\n",
    "    \"{input}\"\n",
    "])\n",
    "rag_chain={'context': retriever, 'input': RunnablePassthrough()} | prompt | llm | parser\n",
    "\n",
    "response=rag_chain.invoke(\"Tell me the difference between the two document versions, also verify if they using the same model? , also list any changes relating to training, testing or anything to do with variables\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document excerpts only provided details for the time ranges in version 4.0. Here's a summary for that version:\n",
      "\n",
      "- **Version 4.0**:\n",
      "  - **Development Dataset (Training and Testing)**: January 2021 to September 2023\n",
      "  - **Hold-Out Dataset (Validation)**: January 2021 to September 2023\n",
      "  - **Out-of-Time (OOT) Dataset (Validation and Stability Testing)**: October 2023 to December 2023\n",
      "\n",
      "Unfortunately, the document excerpts provided did not give any information about the time ranges for version 3.0. Therefore, without additional information, I cannot compare the time ranges between version 3.0 and version 4.0.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"What is the time range in the training data, test data and validation data between v3 and v4?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Sampling Methodology - Undersampling vs. Oversampling**:\n",
      "    - **v4**: \"The goods are undersampled in the development set to aid in supervised modeling.\"\n",
      "    - **v3**: \"The bads are oversampled.\" \n",
      "\n",
      "This indicates a change from oversampling of fraudulent (bad) transactions in v3 to undersampling of non-fraudulent (good) transactions in v4 to handle the imbalance in the dataset.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"What is the difference in sampling methodologies?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Stratified Sampling Modifications**:\n",
      "   - **Version 3**: Employs a stratified sample method aimed at generating a representative dataset of the entire US population. It mentions proportionally equal weightage applied to all client data across the strata.\n",
      "     - *Excerpt*: \"Socure uses a stratiﬁed sample method to generate a representative modeling dataset of the entire US population. [...] The sample is proportionally the same across all strata to ensure equal weightage is applied to all client data.\"\n",
      "   - **Version 4**: Also utilizes a stratified sample method but emphasizes ensuring that fraud patterns observed across various clients are representative within each dataset and mentions the use of a consortium.\n",
      "     - *Excerpt*: \"A stratiﬁed sampling method is used as a baseline to ensure that fraud patterns observed across various clients are representative within each dataset. [...] Socure uses a stratiﬁed sampling method based on fraud label and client to generate a representative modeling dataset of our consortium.\"\n",
      "\n",
      "These changes imply a shift in focus from a broad population level in v3 to a more targeted, customer-specific approach in v4.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"What is the difference in sampling methodologies?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In version 4 (V4) of the Address Risk Model, the performance metrics are as follows:\n",
      "\n",
      "- **AUC-ROC**: \n",
      "  - Overall AUC-ROC for the Out-of-Time Set is **90.24%**. This indicates the model's ability to distinguish between good and fraudulent cases.\n",
      "\n",
      "- **Fraud Detection Rates (FDR) / Good-to-Fraud Ratio (G:F)** for various risk depths:\n",
      "  - **0.5% risk depth**: FDR is **16.61%** with a G:F ratio of **2:1**.\n",
      "  - **1% risk depth**: FDR is **24.60%** with a G:F ratio of **3:1**.\n",
      "  - **3% risk depth**: FDR is **41.23%** with a G:F ratio of **6:1**.\n",
      "  - **5% risk depth**: FDR is **50.72%** with a G:F ratio of **9:1**.\n",
      "  - **10% risk depth**: FDR is **66.50%** with a G:F ratio of **14:1**.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"What is the performancein V4, report the AUC and FDRs\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the important differences in feature and variable selection between Address Risk Model v3 and v4:\n",
      "\n",
      "1. **Feature Engineering and Number/Type of Features**\n",
      "   - **Version 3 (v3)**: Over 5,000+ combination variables were evaluated and 150+ selected top predictors were used in models.\n",
      "     - **Excerpt**: \"Over 5,000+ combination variables were evaluated before using 150+ selected top predictors in our models.\"\n",
      "   - **Version 4 (v4)**: A total of 800+ predictors were tested when building the model, with features derived from first name, surname, complete physical address, IP address, and others.\n",
      "     - **Excerpt**: \"Socure generated and tested 800+ predictors when building the current model in addition to existing features derived from the first name, surname, complete physical address, IP address.\"\n",
      "\n",
      "2. **Variable Selection Method**\n",
      "   - **Version 3 (v3)**: Used a Bayesian-based optimizer to identify the optimal number of variables to max accuracy and minimize time variance.\n",
      "     - **Excerpt**: \"Socure uses a Bayesian-based optimizer for further identifying the optimal number of variables, which contributes to achieving maximum accuracy and minimum time variance.\"\n",
      "   - **Version 4 (v4)**: Variable natural selection/ranking is done by the primary model during training, based on statistical measures like Information Value and Weight of Evidence (WoE).\n",
      "     - **Excerpt**: \"Natural variable selection/ranking is done by the primary model during training.\"\n",
      "\n",
      "These differences highlight a shift from a more expansive initial evaluation of features in v3 to a more structured and direct selection and ranking process in v4.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"Tell me about the feature selections and variable selections in the new and old?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the differences concerning training, testing, and validation data ranges between version 3 and version 4 of the model report:\n",
      "\n",
      "1. **Training Data Ranges for v3:**\n",
      "   - The training dataset used data from **October 2017 through April 2021** as noted: \n",
      "     - \"Socure used data from October 2017 through November 2021.\"\n",
      "     - \"The development data consists of all applications and transactions for the period of October 2017 to April 2021 with tagged frauds.\"\n",
      "\n",
      "2. **Training Data Ranges for v4:**\n",
      "   - The training dataset used data from **January 2021 through December 2023** as noted:\n",
      "     - \"Socure used data from January 2021 through December 2023.\"\n",
      "     - \"The dataset used to train and test and tune the model from January 2021 to December 2023.\"\n",
      "\n",
      "3. **Validation Data Ranges for v3:**\n",
      "   - Validation was conducted on data from **February 2020 to November 2021**:\n",
      "     - \"We then validated the models on transactions and tagged frauds from February 2020 to November 2021.\"\n",
      "\n",
      "4. **Validation Data Ranges for v4:**\n",
      "   - The validation was carried out using a hold-out dataset from **January 2021 to September 2023** and an out-of-time dataset from **October 2023 to December 2023**:\n",
      "     - \"Hold-out dataset, a part of historical data from the development set time period (January 2021 - Sep 2023).\"\n",
      "     - \"Out-of-Time (OOT) dataset from October 2023 to December 2023.\"\n",
      "\n",
      "These differences highlight the expansion and adjustment in the datasets used for developing and validating the model from version 3 to version 4.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"from what period is the training, testing and validation data of be specific and tell me the exact to and from times ?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided excerpts include detailed model performance for Address Risk Version 4.0:\n",
      "\n",
      "- **Model Performance (V4) - AUC-ROC:**\n",
      "  - Development Set: 92.18%\n",
      "  - Hold-Out Set: 91.56%\n",
      "  - Out-of-Time Set: 90.24%\n",
      "\n",
      "- **FDR (Fraud Detection Rate) / Good-to-Fraud Ratio (G:F) for V4:**\n",
      "\n",
      "  - **Development Set:**\n",
      "    - 0.5% Risk Depth: 25.33% / 1:1\n",
      "    - 1% Risk Depth: 36.89% / 2:1\n",
      "    - 3% Risk Depth: 56.14% / 4:1\n",
      "    - 5% Risk Depth: 65.69% / 7:1\n",
      "    - 10% Risk Depth: 78.32% / 12:1\n",
      "\n",
      "  - **Hold-Out Set:**\n",
      "    - 0.5% Risk Depth: 21.94% / 1:1\n",
      "    - 1% Risk Depth: 32.36% / 2:1\n",
      "    - 3% Risk Depth: 51.88% / 5:1\n",
      "    - 5% Risk Depth: 61.09% / 7:1\n",
      "    - 10% Risk Depth: 74.91% / 13:1\n",
      "\n",
      "  - **Out-of-Time Set:**\n",
      "    - 0.5% Risk Depth: 16.61% / 2:1\n",
      "    - 1% Risk Depth: 24.60% / 3:1\n",
      "    - 3% Risk Depth: 41.23% / 6:1\n",
      "    - 5% Risk Depth: 50.72% / 9:1\n",
      "    - 10% Risk Depth: 66.50% / 14:1\n",
      "\n",
      "As for the FDR for 50% of the riskiest population, the document does not provide this specific metric. You might need additional information to determine the FDR for a 50% risk depth.\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke(\"Tell me the performance of the model for V4 also provide the FDR for the 50% of the riskiest population? or other FDRs for training , testing and validation data\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
