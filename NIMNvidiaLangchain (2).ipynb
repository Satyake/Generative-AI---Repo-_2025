{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ae8f15-e7aa-43e2-bfa0-48510350afda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4c9fdd2-2352-4c7b-863b-deab6cf1f066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -q install openai python-dotenv langchain_nvidia_ai_endpoints langchain_community faiss-cpu pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc79af82-e0d2-46b2-8e09-609286a2af6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "os.environ['NVIDIA_API_KEY']=os.getenv('NVIDIA_API_KEY')\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = os.getenv('NVIDIA_API_KEY')\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"deepseek-ai/deepseek-r1\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"Provide me an essay on ML\"}],\n",
    "  temperature=0.6,\n",
    "  top_p=1,\n",
    "  max_tokens=4096,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "      if chunk.choices[0].delta.content is not None:\n",
    "            print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "775693c2-3653-495b-a563-1d3e57c4ceae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RAG_NVIDIA_NIM.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  RAG_NVIDIA_NIM.py\n",
    "import streamlit as st\n",
    "import os \n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Load the Nvidia API key\n",
    "os.environ['NVIDIA_API_KEY']=os.getenv('NVIDIA_API_KEY')\n",
    "llm=ChatNVIDIA(model_name='meta/llama3-70b-instruct')\n",
    "\n",
    "def vector_embedding():\n",
    "    if \"vectors\" not in st.session_state:\n",
    "        st.session_state.embeddings=NVIDIAEmbeddings()\n",
    "        st.session_state.loader=PyPDFDirectoryLoader('./us_census')\n",
    "        st.session_state.docs=st.session_state.loader.load()\n",
    "        st.session_state.text_splitter=RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
    "        st.session_state.final_documents=st.session_state.text_splitter.split_documents(st.session_state.docs)\n",
    "        st.session_state.vectors=FAISS.from_documents(st.session_state.final_documents,st.session_state.embeddings)\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Answer the questions based on the provided context only.\n",
    "Please provide the most accurate response based on the question\n",
    "<context>\n",
    "{context}\n",
    "<context>\n",
    "Questions:{input}\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt1=st.text_input(\"Enter your question from documents\")\n",
    "if st.button(\"Document Embedding\"):\n",
    "    vector_embedding()\n",
    "    st.write(\" FAISS Vector Store DB is ready with Nvidia Embeddings\")\n",
    "if prompt1:\n",
    "    document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "    retriever=st.session_state.vectors.as_retriever()\n",
    "    retrieval_chain=create_retrieval_chain(retriever,document_chain)\n",
    "    response=retrieval_chain.invole({'input':prompt1})\n",
    "    st.write(response['answer'])\n",
    "    \n",
    "    #streamlit expander\n",
    "    with st.expander(\"Document Similarity Search\"):\n",
    "        for i , doc in enumerate(response[\"context\"]):\n",
    "            st.write(doc.page_content)\n",
    "            st.write(\"------------\")\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4004bb-8c38-4614-94a3-ef6d0b630340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
